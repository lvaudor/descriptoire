[["résumer-linformation-par-des-métriques.html", "Chapitre 4 Résumer l’information par des métriques 4.1 Fréquences d’occurrence 4.2 Co-occurrences, corrélations 4.3 TF-IDF 4.4 Spécificités", " Chapitre 4 Résumer l’information par des métriques Avant de réaliser quelques graphiques pour montrer le contenu lexical de nos textes il faudra la plupart du temps quelques calculs basiques sur nos données (par exemple agréger les données pour obtenir les fréquences d’occurrence des termes). Pour réaliser ces quelques transformations on peut généralement utiliser les fonctions de dplyr. Ici, on repart du tableau suivant tib_lemmes &lt;- read_csv2(&quot;data/ministereco_tib_lemmes.csv&quot;) %&gt;% na.omit() head(tib_lemmes) ## # A tibble: 6 × 4 ## doc word lemma type ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 doc1 amont amont nom ## 2 doc1 réunions réunion nom ## 3 doc1 informelles informel adj ## 4 doc1 ministres ministre nom ## 5 doc1 tiendront tenir ver ## 6 doc1 janvier janvier nom On pourrait être amené à calculer la fréquence des mots calculer la fréquence des mots pour différentes parties du corpus ne garder que les \\(n\\) mots les plus fréquents etc. 4.1 Fréquences d’occurrence freq_lemmes &lt;- tib_lemmes %&gt;% group_by(lemma) %&gt;% summarise(freq=n()) %&gt;% arrange(desc(freq)) %&gt;% na.omit() head(freq_lemmes) ## # A tibble: 6 × 2 ## lemma freq ## &lt;chr&gt; &lt;int&gt; ## 1 ministre 5946 ## 2 transition 4254 ## 3 écologique 4007 ## 4 projet 3896 ## 5 mettre 3157 ## 6 presse 3129 Ici, je n’en ai pas besoin (mon jeu de données est tout petit) mais je pourrais également filtrer les données pour ne garder qu’une fréquence minimale, ou ne garder que les \\(n\\) mots les plus fréquents… freq_lemmes %&gt;% filter(freq&gt;=5) ## # A tibble: 4,469 × 2 ## lemma freq ## &lt;chr&gt; &lt;int&gt; ## 1 ministre 5946 ## 2 transition 4254 ## 3 écologique 4007 ## 4 projet 3896 ## 5 mettre 3157 ## 6 presse 3129 ## 7 permettre 2896 ## 8 national 2831 ## 9 territoire 2823 ## 10 transport 2646 ## # … with 4,459 more rows freq_lemmes %&gt;% top_n(3,freq) ## # A tibble: 3 × 2 ## lemma freq ## &lt;chr&gt; &lt;int&gt; ## 1 ministre 5946 ## 2 transition 4254 ## 3 écologique 4007 Pour faciliter ce processus que l’on est amené à réaliser fréquemment pour analyser des données textuelles, j’ai créé une fonction tidy_frequencies (package mixr) qui regroupe l’ensemble des étapes: mixr::tidy_frequencies(tib_lemmes,lemma,top_freq=10) ## # A tibble: 10 × 2 ## lemma freq ## &lt;chr&gt; &lt;int&gt; ## 1 ministre 5946 ## 2 transition 4254 ## 3 écologique 4007 ## 4 projet 3896 ## 5 mettre 3157 ## 6 presse 3129 ## 7 permettre 2896 ## 8 national 2831 ## 9 territoire 2823 ## 10 transport 2646 4.2 Co-occurrences, corrélations Si l’on s’intéresse non plus seulement à la fréquence individuelle des termes mais qu’on cherche à caractériser les termes qui sont souvent employés ensemble (au sein d’un même commentaire par exemple) on peut utiliser les fonctions du package widyr. library(widyr) mots_cooc &lt;- tib_lemmes %&gt;% pairwise_count(lemma,feature=doc,sort=TRUE) head(mots_cooc) ## # A tibble: 6 × 3 ## item1 item2 n ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 écologique transition 1679 ## 2 transition écologique 1679 ## 3 transition ministre 1511 ## 4 ministre transition 1511 ## 5 écologique ministre 1484 ## 6 ministre écologique 1484 motA:T motA:F Total motB:T \\(N_{TT}\\) \\(N_{TF}\\) \\(N_{T.}\\) motB:F \\(N_{FT}\\) \\(N_{FF}\\) \\(N_{F.}\\) Total \\(N_{.T}\\) \\(N_{.F}\\) N \\[Cor=\\frac{N_{TT}N_{FF}-N_{TF}N_{FT}}{\\sqrt{N_{T.}N_{F.}N_{.F}N_{.T}}}\\] mots_cors &lt;- tib_mots_nonvides %&gt;% pairwise_cor(lemma,auteur,sort=TRUE) head(mots_cors) ## # A tibble: 6 × 3 ## item1 item2 correlation ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 pain mur 1 ## 2 dur mur 1 ## 3 nourrir mur 1 ## 4 mur pain 1 ## 5 dur pain 1 ## 6 nourrir pain 1 Pour la suite on va joindre les tableaux mots_cooc et mot_cors mots_cooc &lt;- left_join(mots_cooc, mots_cors, by=c(&quot;item1&quot;,&quot;item2&quot;)) 4.3 TF-IDF Le \\(TF-IDF\\) (pour “term frequency-inverse document frequency”) est une métrique qui reflète l’importance relative d’un mot dans un document. TF{d,w} est la fréquence (ou nombre d’occurrences) du terme \\(w\\) dans le document \\(d\\). Elle mesure l’importance du terme dans le document. IDF{d,w} est la fréquence inverse de document. Elle mesure l’importance du terme dans le corpus. Elle se calcule comme suit, où \\(D\\) est le nombre total de documents et \\(\\{d_j: w_i \\in d_j\\}\\) est le nombre de documents qui contiennent le terme \\(w_i\\): \\[ IDF_{w}=log\\left(\\frac{D}{\\{d_j: w_i \\in d_j\\}}\\right)\\] Le \\(TF-IDF\\) se calcule comme le produit \\(TF*IDF\\). La multiplication par \\(IDF\\) sert notamment à minimiser la valeur de \\(TF-IDF\\) pour les termes les plus fréquents, qu’on suppose peu discriminants. tib_tfidf &lt;- tib_lemmes %&gt;% count(doc,lemma) %&gt;% bind_tf_idf(lemma,doc,n) %&gt;% arrange(desc(tf_idf)) head(tib_tfidf, n=15) ## # A tibble: 15 × 6 ## doc lemma n tf idf tf_idf ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 doc2162 ficher 1 0.5 5.19 2.59 ## 2 doc2000 french 1 0.5 4.20 2.10 ## 3 doc2162 télécharger 1 0.5 4.20 2.10 ## 4 doc2574 télécharger 1 0.5 4.20 2.10 ## 5 doc2237 gille 1 0.333 5.32 1.77 ## 6 doc2574 consulter 1 0.5 3.22 1.61 ## 7 doc2660 transformation 1 0.5 2.51 1.26 ## 8 doc874 traversier 4 0.154 7.96 1.22 ## 9 doc2558 joint 1 0.2 5.48 1.10 ## 10 doc1356 mirepoix 4 0.154 6.86 1.06 ## 11 doc324 décryptage 1 0.143 7.27 1.04 ## 12 doc2237 député 1 0.333 3.06 1.02 ## 13 doc2710 pack 1 0.125 7.27 0.909 ## 14 doc2558 pièce 1 0.2 4.53 0.905 ## 15 doc443 américain 1 0.167 5.40 0.899 4.4 Spécificités Le package textometry (réalisé par l’équipe TXM) comprend une fonction qui permet de calculer des scores de spécificité. Le but de ce score est (comme pour le TF-IDF) d’identifier les termes spécifiques à une partie du corpus. Pour plus de compatibilité avec le tidyverse on peut utiliser la fonction tidy_specificities() qui reformatte la sortie de cette fonction pour renvoyer un résultat tabulaire conforme à la logique “tidyverse”. Par convention, on interprète un terme comme étant spécifique à une partie du corpus quand son score est supérieur à 2. mixr::tidy_specificities(tib_lemmes,lemma, doc) ## # A tibble: 24,243,204 × 4 ## lemma doc spec n ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 &quot;communauté &quot; &quot;doc1804&quot; 91.8 NA ## 2 &quot;éviter &quot; &quot;doc1574&quot; 73.5 NA ## 3 &quot;fashion &quot; &quot;doc1560&quot; 71.8 NA ## 4 &quot;éviter &quot; &quot;doc337 &quot; 64.1 NA ## 5 &quot;allocataire &quot; &quot;doc356 &quot; 62.3 NA ## 6 &quot;éviter &quot; &quot;doc327 &quot; 60.8 NA ## 7 &quot;heure &quot; &quot;doc2901&quot; 60.2 NA ## 8 &quot;sol &quot; &quot;doc73 &quot; 59.6 NA ## 9 &quot;commun &quot; &quot;doc1804&quot; 58.9 NA ## 10 &quot;chantilly &quot; &quot;doc257 &quot; 58.9 NA ## # … with 24,243,194 more rows "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
